Music Country of OriginClassifier using Spectrograms purpose:

The purpose of this project is to create a modelthat can classify a song's country of origin based on the mel-spectrogram of the song. 

In creating the dataset for this project, I experiemented with a few different methods:

The first method (failure) involved parsing through the universal_top_songs.csv file trying to find countries associated with songs by finding songs that only appear popular in once country, and also finding the country from which a given song is the most popular in and combining these two lists. This was a failure because the songs arent always associated with their country of origin, and then having to take that data and find corresponding audio files in the FMA archive eliminates a lot of songs and doesn't even capture the songs that are popular in big countries like the US. 


The method that I think will work best is to parse directly throuhg the FMA metadata and extract the audio paths and the corresponding location coordinates. Using the geopy module, I can find the country of the audio file and construct a new csv of audio paths and countries. From there I can balance the number of occurences of each country by splitting up each 30 second audio clip into 5 second segments and then creating a spectrogram for each segment. This should give me a dataset of balanced countries with their corresponding spectrograms. During this process I can also augment the dataset by applying random pitch shifts to the spectrograms. 


The issue that arises with this method is that the FMA-small and medium datasets are heavily unbalanced with songs from the US and UK. This is a problem because the model will be overfit to these countries and not generalize to other countries and also means there might be low variation in the data because I am not able to use as many classes, and the majority classes are all Western countries, who may have similar music. 
To combat this, I can downsample the US, UK and other big countries' songs to be the same number as the least popular country in the dataset. I can then augment the dataset by splitting up the audio clips into smaller segments. Finally to get the spectrograms of the segmented audio, I use librosa.load to convert the audio clips into arrays. And then A custom AudioDataset class that converts the arrays into torch.FloatTensor objects and normalizes the data during the loading process.  This is done in the official_data_developer.py file. Inside this file you can adjust the number of countries from which to sample the data, and experiment with training the model on different numbers of countries. Drawbacks of this are that the number of songs for country is heavly unbalanced so the model will not have enough data to train with.


The training process is done in the train_model.py file. I use the PyTorch Lightning library to help with the training process. And I use the custom TensorBoard object that you provided in the victoresque repoto help with the logging process. 
My forward pass is in the model.py file. I use a 1D CNN with 3 convolutional blocks and a final fully connected layer to classify the song into one of 3 countries. In between the first and second convolutional blocks I use a temporal attention mechanism to help the model. Between the third block and the final fully connected layers I use a spatial attention mechanism to help the model focus on the most important parts of the spectrogram. 


the necessary dependancies to create the data and train the modelare in SpectrogramClassifier/environment.yml
to create the environment run: 
module load miniconda3/20250410
conda env create -f environment.yml

to train the model run: 

python SpectrogramClassifier/train_model.py

this saves the model's state_dict with the specified filename at the bottom of the train_model to the models folder (most current model path is 'models/model_v23.pth'). 

Here is a visualization of the training process (generated by the visualize_training.py file, which accesses the logs saved in lightning_logs/version_197/metrics.csv)
if the png doesn't load check the loss_plots directory for training_plot197_CNN_attention.png:
![alt text](image.png)


To test the model run the run_model.py file:
python SpectrogramClassifier/run_model.py
or use the evaluation.ipynb file to evaluate the model on different test sets. 

From this we can see that the model is pretty accurate, scoring a 0.89 accuracy on the test set. Misclassifications are
pretty evenly distributed across the classes (check the confusion matrixes in the evaluation.ipynb file). 
results:
![alt text](image.png)  



To see the data_loader in use check out the data_demo.ipynb file. 

The limitations of this model are


