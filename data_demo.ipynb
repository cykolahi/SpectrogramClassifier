{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official_data_loader import AudioDataLoader, AudioDataset, save_dataset\n",
    "\n",
    "data_path = '/projects/dsci410_510/Kolahi_data_temp/expanded_dataset_v21.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset split complete:\n",
      "Training set: 4298 samples\n",
      "Validation set: 921 samples\n",
      "Test set: 921 samples\n"
     ]
    }
   ],
   "source": [
    "data_loader = AudioDataLoader(data_path)\n",
    "train_loader, val_loader, test_loader = data_loader.create_train_val_test_split(random_state=42)\n",
    "save_dataset(train_loader, '/projects/dsci410_510/Kolahi_data_temp/train_dataset.pkl')\n",
    "save_dataset(val_loader, '/projects/dsci410_510/Kolahi_data_temp/val_dataset.pkl')\n",
    "save_dataset(test_loader, '/projects/dsci410_510/Kolahi_data_temp/test_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data country distribution:\n",
      "United Kingdom    1442\n",
      "United States     1432\n",
      "Canada            1424\n",
      "Name: count, dtype: int64\n",
      "Val data country distribution:\n",
      "United Kingdom    309\n",
      "United States     307\n",
      "Canada            305\n",
      "Name: count, dtype: int64\n",
      "Test data country distribution:\n",
      "United Kingdom    309\n",
      "United States     307\n",
      "Canada            305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "train_data = pd.read_pickle('/projects/dsci410_510/Kolahi_data_temp/train_dataset.pkl')\n",
    "val_data = pd.read_pickle('/projects/dsci410_510/Kolahi_data_temp/val_dataset.pkl')\n",
    "test_data = pd.read_pickle('/projects/dsci410_510/Kolahi_data_temp/test_dataset.pkl')\n",
    "\n",
    "print(\"Train data country distribution:\")\n",
    "print(pd.Series(train_data['countries']).value_counts())\n",
    "\n",
    "print(\"Val data country distribution:\")\n",
    "print(pd.Series(val_data['countries']).value_counts())\n",
    "\n",
    "print(\"Test data country distribution:\")\n",
    "print(pd.Series(test_data['countries']).value_counts())\n",
    "\n",
    "## In the training process, skip the save_dataset step and just use the data_loader to create the train_loader, val_loader, and test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
